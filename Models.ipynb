{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/homebrew/lib/python3.11/site-packages (1.7.6)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from xgboost) (1.10.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Clone the Git repository and navigate to the project directory\n",
    "#!git clone https://github.com/DanteMillerDS/MPA_Predictor.git\n",
    "#%cd MPA_Predictor\n",
    "\n",
    "# Install required packages\n",
    "!pip install xgboost\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import uuid\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(1000)\n",
    "tf.random.set_seed(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = dict()\n",
    "file_paths[0] = [\"data/s11_dB_freq.txt\"]\n",
    "\n",
    "def process_file(file_path):\n",
    "    datasets = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        current_dataset = []\n",
    "        for line in file:\n",
    "            if line.startswith(\"#Parameters\"):\n",
    "                if current_dataset:\n",
    "                    datasets.append(current_dataset)\n",
    "                    current_dataset = []\n",
    "                params_str = line[line.index(\"{\") + 1:line.index(\"}\")]\n",
    "                params = dict(param.split('=') for param in params_str.split(';'))\n",
    "                current_dataset.append(params)\n",
    "            elif line.startswith(\"#\"):\n",
    "                continue\n",
    "            else:\n",
    "                data = line.strip().split('\\t')\n",
    "                current_dataset.append(data)\n",
    "        if current_dataset:\n",
    "            datasets.append(current_dataset)\n",
    "    data = []\n",
    "    for dataset in datasets:\n",
    "        permittivity_values = dataset[0]\n",
    "        df_data = dataset[1:]\n",
    "        s_parameter_name = file_path.split(\"_parameter_data_for_\")[0]\n",
    "        df = pd.DataFrame(df_data, columns=[\"Frequency\", f\"{s_parameter_name}\"])\n",
    "        df[\"ID\"] = str(uuid.uuid4())[:8]\n",
    "        for key, value in permittivity_values.items():\n",
    "            df[key.replace(\" \", \"\")] = value\n",
    "        data.append(df)\n",
    "    return data\n",
    "all_combined_data = []\n",
    "for index in file_paths:\n",
    "    for file in file_paths[index]:\n",
    "        combined_data = process_file(file)\n",
    "        combined_data = pd.concat(combined_data, ignore_index=True)\n",
    "        all_combined_data.append(combined_data)\n",
    "array = []\n",
    "group_size = 4\n",
    "for i in range(0, len(all_combined_data), group_size):\n",
    "    combined_dataframe = pd.concat(all_combined_data[i:i+group_size], axis=1)\n",
    "    combined_dataframe.reset_index(drop=True, inplace=True)\n",
    "    array.append(combined_dataframe)\n",
    "training_dataframe = pd.concat(array, axis=0)\n",
    "training_dataframe.reset_index(drop=True, inplace=True)\n",
    "training_dataframe = training_dataframe.loc[:, ~training_dataframe.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Frequency', 'data/s11_dB_freq.txt', 'ID', 'rprobe', 'rin', 'er22',\n",
      "       'er2', 'cl', 'r0', 'w', 'L', 't', 'h', 'wy', 'wx', 'er11', 'er1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(training_dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>data/s11_dB_freq.txt</th>\n",
       "      <th>ID</th>\n",
       "      <th>rprobe</th>\n",
       "      <th>rin</th>\n",
       "      <th>er22</th>\n",
       "      <th>er2</th>\n",
       "      <th>cl</th>\n",
       "      <th>r0</th>\n",
       "      <th>w</th>\n",
       "      <th>L</th>\n",
       "      <th>t</th>\n",
       "      <th>h</th>\n",
       "      <th>wy</th>\n",
       "      <th>wx</th>\n",
       "      <th>er11</th>\n",
       "      <th>er1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1001</td>\n",
       "      <td>100100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1.0000000000000</td>\n",
       "      <td>-0.16391811348113</td>\n",
       "      <td>6bd7f8e4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "      <td>10</td>\n",
       "      <td>1.8</td>\n",
       "      <td>41.662565887693</td>\n",
       "      <td>66.660105420309</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "      <td>100100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Frequency data/s11_dB_freq.txt        ID  rprobe     rin   \n",
       "count            100100               100100    100100  100100  100100  \\\n",
       "unique             1001               100100       100       1       1   \n",
       "top     1.0000000000000    -0.16391811348113  6bd7f8e4     0.4     1.5   \n",
       "freq                100                    1      1001  100100  100100   \n",
       "\n",
       "          er22     er2      cl      r0                w                L   \n",
       "count   100100  100100  100100  100100           100100           100100  \\\n",
       "unique       1       1       1       1              100              100   \n",
       "top       0.01    2.55      10     1.8  41.662565887693  66.660105420309   \n",
       "freq    100100  100100  100100  100100             1001             1001   \n",
       "\n",
       "             t       h      wy      wx    er11     er1  \n",
       "count   100100  100100  100100  100100  100100  100100  \n",
       "unique       1       1       1       1       1       1  \n",
       "top        0.2     1.6     200     200    0.01    2.55  \n",
       "freq    100100  100100  100100  100100  100100  100100  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>data/s11_dB_freq.txt</th>\n",
       "      <th>ID</th>\n",
       "      <th>rprobe</th>\n",
       "      <th>rin</th>\n",
       "      <th>er22</th>\n",
       "      <th>er2</th>\n",
       "      <th>cl</th>\n",
       "      <th>r0</th>\n",
       "      <th>w</th>\n",
       "      <th>L</th>\n",
       "      <th>t</th>\n",
       "      <th>h</th>\n",
       "      <th>wy</th>\n",
       "      <th>wx</th>\n",
       "      <th>er11</th>\n",
       "      <th>er1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000000000000</td>\n",
       "      <td>-0.16391811348113</td>\n",
       "      <td>6bd7f8e4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "      <td>10</td>\n",
       "      <td>1.8</td>\n",
       "      <td>41.662565887693</td>\n",
       "      <td>66.660105420309</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0089999437332</td>\n",
       "      <td>-0.13135824869362</td>\n",
       "      <td>6bd7f8e4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "      <td>10</td>\n",
       "      <td>1.8</td>\n",
       "      <td>41.662565887693</td>\n",
       "      <td>66.660105420309</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0180000066757</td>\n",
       "      <td>-0.068439952547044</td>\n",
       "      <td>6bd7f8e4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "      <td>10</td>\n",
       "      <td>1.8</td>\n",
       "      <td>41.662565887693</td>\n",
       "      <td>66.660105420309</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0269999504089</td>\n",
       "      <td>-0.013417551672601</td>\n",
       "      <td>6bd7f8e4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "      <td>10</td>\n",
       "      <td>1.8</td>\n",
       "      <td>41.662565887693</td>\n",
       "      <td>66.660105420309</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0360000133514</td>\n",
       "      <td>-0.00015245797012125</td>\n",
       "      <td>6bd7f8e4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "      <td>10</td>\n",
       "      <td>1.8</td>\n",
       "      <td>41.662565887693</td>\n",
       "      <td>66.660105420309</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Frequency  data/s11_dB_freq.txt        ID rprobe  rin  er22   er2   \n",
       "0  1.0000000000000     -0.16391811348113  6bd7f8e4    0.4  1.5  0.01  2.55  \\\n",
       "1  1.0089999437332     -0.13135824869362  6bd7f8e4    0.4  1.5  0.01  2.55   \n",
       "2  1.0180000066757    -0.068439952547044  6bd7f8e4    0.4  1.5  0.01  2.55   \n",
       "3  1.0269999504089    -0.013417551672601  6bd7f8e4    0.4  1.5  0.01  2.55   \n",
       "4  1.0360000133514  -0.00015245797012125  6bd7f8e4    0.4  1.5  0.01  2.55   \n",
       "\n",
       "   cl   r0                w                L    t    h   wy   wx  er11   er1  \n",
       "0  10  1.8  41.662565887693  66.660105420309  0.2  1.6  200  200  0.01  2.55  \n",
       "1  10  1.8  41.662565887693  66.660105420309  0.2  1.6  200  200  0.01  2.55  \n",
       "2  10  1.8  41.662565887693  66.660105420309  0.2  1.6  200  200  0.01  2.55  \n",
       "3  10  1.8  41.662565887693  66.660105420309  0.2  1.6  200  200  0.01  2.55  \n",
       "4  10  1.8  41.662565887693  66.660105420309  0.2  1.6  200  200  0.01  2.55  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_columns = [\"Frequency\",\"data/s11_dB_freq.txt\",\"h\",\"t\",\"er11\",\"er1\",\"w\",\"L\"]\n",
    "training_dataframe = training_dataframe[needed_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "L2 = 0.0001\n",
    "WD = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for column in training_dataframe.columns:\n",
    "    if column not in [\"Permittivity_Real\",\"Permittivity_Imaginary\",\"ID\",\"Orientation\",\"Frequency\"]:\n",
    "        columns.append(column)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_dataframe[columns].values\n",
    "y_train = training_dataframe[['Permittivity_Real', 'Permittivity_Imaginary']].values\n",
    "selected_indices = np.random.permutation(len(training_dataframe))\n",
    "X_selected = X_train[selected_indices]\n",
    "y_selected = y_train[selected_indices]\n",
    "grouped_indices = {}\n",
    "for idx in selected_indices:\n",
    "    row = training_dataframe.iloc[idx]\n",
    "    orientation = row['Orientation']\n",
    "    frequency = row['Frequency']\n",
    "    key = (orientation, frequency)\n",
    "    if key not in grouped_indices:\n",
    "        grouped_indices[key] = []\n",
    "    grouped_indices[key].append(idx)\n",
    "X_train_indices = []\n",
    "X_val_indices = []\n",
    "X_test_indices = []\n",
    "for key, indices in grouped_indices.items():\n",
    "    train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    val_indices, test_indices = train_test_split(val_indices, test_size=0.2, random_state=42)\n",
    "    X_train_indices.extend(train_indices)\n",
    "    X_val_indices.extend(val_indices)\n",
    "    X_test_indices.extend(test_indices)\n",
    "X_train = X_selected[X_train_indices]\n",
    "y_train = y_selected[X_train_indices]\n",
    "X_val = X_selected[X_val_indices]\n",
    "y_val = y_selected[X_val_indices]\n",
    "X_test_indices.sort()\n",
    "X_test = X_selected[X_test_indices]\n",
    "y_test = y_selected[X_test_indices]\n",
    "X_train = X_train.astype(float)\n",
    "y_train = y_train.astype(float)\n",
    "X_val = X_val.astype(float)\n",
    "y_val = y_val.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "y_test = y_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_train = len(X_train)\n",
    "num_obs_val = len(X_val)\n",
    "num_obs_test = len(X_test)\n",
    "total_obs = num_obs_train + num_obs_val + num_obs_test\n",
    "data = {'Dataset': ['Training', 'Validation', 'Test', 'Total'],\n",
    "        'Number of Observations': [num_obs_train, num_obs_val, num_obs_test, total_obs]}\n",
    "observations_table = pd.DataFrame(data)\n",
    "print(observations_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_orientations = training_dataframe.loc[X_train_indices, 'Orientation']\n",
    "selected_frequencies = training_dataframe.loc[X_train_indices, 'Frequency']\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(selected_orientations, bins=10, color='blue', edgecolor='black')\n",
    "plt.title('Training: Histogram of Selected Orientations')\n",
    "plt.xlabel('Orientation')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(selected_frequencies, bins=20, color='green', edgecolor='black')\n",
    "plt.title('Training: Histogram of Selected Frequencies')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "selected_orientations = training_dataframe.loc[X_val_indices, 'Orientation']\n",
    "selected_frequencies = training_dataframe.loc[X_val_indices, 'Frequency']\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(selected_orientations, bins=10, color='blue', edgecolor='black')\n",
    "plt.title('Validation: Histogram of Selected Orientations')\n",
    "plt.xlabel('Orientation')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(selected_frequencies, bins=20, color='green', edgecolor='black')\n",
    "plt.title('Validation: Histogram of Selected Frequencies')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "selected_orientations = training_dataframe.loc[X_test_indices, 'Orientation']\n",
    "selected_frequencies = training_dataframe.loc[X_test_indices, 'Frequency']\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(selected_orientations, bins=10, color='blue', edgecolor='black')\n",
    "plt.title('Testing: Histogram of Selected Orientations')\n",
    "plt.xlabel('Orientation')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(selected_frequencies, bins=20, color='green', edgecolor='black')\n",
    "plt.title('Testing: Histogram of Selected Frequencies')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss(y_true, y_pred):\n",
    "    squared_error = tf.square(y_true - y_pred)\n",
    "    mean_squared_error = tf.reduce_mean(squared_error)\n",
    "    root_mean_squared_error = tf.sqrt(mean_squared_error)\n",
    "    return root_mean_squared_error\n",
    "\n",
    "nn_model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],),kernel_initializer='he_uniform', kernel_regularizer=tf.keras.regularizers.l2(L2)),\n",
    "    keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform',kernel_regularizer=tf.keras.regularizers.l2(L2)),\n",
    "    keras.layers.Dense(32, activation='relu', kernel_initializer='he_uniform',kernel_regularizer=tf.keras.regularizers.l2(L2)),\n",
    "    keras.layers.Dense(16, activation='relu', kernel_initializer='he_uniform',kernel_regularizer=tf.keras.regularizers.l2(L2)),\n",
    "    keras.layers.Dense(y_train.shape[1], activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "nn_model.compile(optimizer=tf.optimizers.Adam(learning_rate=L2,weight_decay=WD),\n",
    "              loss=[rmse_loss],\n",
    "              metrics=[tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError()])\n",
    "nn_model.summary()\n",
    "history = nn_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=1001,shuffle=True)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "plt.title('Moon Rock FNN: Mean Absolute Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Moon Rock FNN: Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(n_jobs=-1,device=\"gpu\",n_estimators=250,eval_metric=mean_absolute_error,verbosity=3,max_depth=5)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_model = tabnet(n_jobs=-1,device=\"gpu\",n_estimators=250,eval_metric=mean_absolute_error,verbosity=3,max_depth=5)\n",
    "tabnet_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1001\n",
    "y_pred_nn = nn_model.predict(X_test)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_tab = tabnet_model.predict(X_test)\n",
    "\n",
    "y_pred_nn = y_pred_nn.reshape(-1, batch_size, y_pred_nn.shape[-1])\n",
    "y_pred_xgb = y_pred_xgb.reshape(-1, batch_size, y_pred_xgb.shape[-1])\n",
    "y_pred_tab = y_pred_tab.reshape(-1, batch_size, y_pred_tab.shape[-1])\n",
    "\n",
    "y_pred_nn = np.mean(y_pred_nn, axis=1)\n",
    "y_pred_xgb = np.mean(y_pred_xgb, axis=1)\n",
    "y_pred_tab = np.mean(y_pred_tab, axis=1)\n",
    "\n",
    "y_test = np.mean(y_test, axis=1)\n",
    "\n",
    "y_pred_0_nn, y_test_0 = y_pred_nn[:, 0], y_test[:, 0]\n",
    "y_pred_1_nn, y_test_1 = y_pred_nn[:, 1], y_test[:, 1]\n",
    "y_pred_0_xgb, _ = y_pred_xgb[:, 0], _\n",
    "y_pred_1_xgb, _ = y_pred_xgb[:, 1], _\n",
    "y_pred_0_tab, _ = y_pred_tab[:, 0], _\n",
    "y_pred_1_tab, _ = y_pred_tab[:, 1], _\n",
    "\n",
    "y_pred_0_nn = np.clip(y_pred_0_nn, 0.0, 0.2)\n",
    "y_pred_1_nn = np.clip(y_pred_1_nn, 0.0, 0.2)\n",
    "y_pred_0_xgb = np.clip(y_pred_0_xgb, 0.0, 0.2)\n",
    "y_pred_1_xgb = np.clip(y_pred_1_xgb, 0.0, 0.2)\n",
    "y_pred_0_tab = np.clip(y_pred_0_tab, 0.0, 0.2)\n",
    "y_pred_1_tab = np.clip(y_pred_1_tab, 0.0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_xgb = mean_squared_error(y_test_0, y_pred_0_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test_0, y_pred_0_xgb)\n",
    "r_squared_xgb = r2_score(y_test_0, y_pred_0_xgb)\n",
    "mse_nn = mean_squared_error(y_test_0, y_pred_0_nn)\n",
    "mae_nn = mean_absolute_error(y_test_0, y_pred_0_nn)\n",
    "r_squared_nn = r2_score(y_test_0, y_pred_0_nn)\n",
    "mse_tab = mean_squared_error(y_test_0, y_pred_0_tab)\n",
    "mae_tab = mean_absolute_error(y_test_0, y_pred_0_tab)\n",
    "r_squared_tab = r2_score(y_test_0, y_pred_0_tab)\n",
    "print(\"Metrics for XGBoost Model:\")\n",
    "print(f\"MSE: {mse_xgb:.4f}\")\n",
    "print(f\"MAE: {mae_xgb:.4f}\")\n",
    "print(f\"R-squared (R²): {r_squared_xgb:.4f}\")\n",
    "print(\"\\nMetrics for FNN Model:\")\n",
    "print(f\"MSE: {mse_nn:.4f}\")\n",
    "print(f\"MAE: {mae_nn:.4f}\")\n",
    "print(f\"R-squared (R²): {r_squared_nn:.4f}\")\n",
    "print(\"\\nMetrics for TabNet Model:\")\n",
    "print(f\"MSE: {mse_tab:.4f}\")\n",
    "print(f\"MAE: {mae_tab:.4f}\")\n",
    "print(f\"R-squared (R²): {r_squared_tab:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(len(y_test_0)), y_test_0, label='Actual', color='blue', alpha=0.7)\n",
    "plt.plot(range(len(y_test_0)), y_pred_0_xgb, label='Predicted (XGBoost)', color='green', alpha=0.7)\n",
    "plt.plot(range(len(y_test_0)), y_pred_0_nn, label='Predicted (FNN)', color='purple', alpha=0.7)\n",
    "plt.plot(range(len(y_test_0)), y_pred_0_tab, label='Predicted (TabNet)', color='green', alpha=0.7)\n",
    "plt.plot([0, len(y_test_0) - 1], [np.mean(y_pred_0_xgb), np.mean(y_pred_0_xgb)], linestyle='dashed', color='red', label='Predicted Mean (XGBoost)')\n",
    "plt.plot([0, len(y_test_0) - 1], [np.mean(y_pred_0_nn), np.mean(y_pred_0_nn)], linestyle='dashed', color='orange', label='Predicted Mean (FNN)')\n",
    "plt.plot([0, len(y_test_0) - 1], [np.mean(y_pred_0_nn), np.mean(y_pred_0_nn)], linestyle='dashed', color='orange', label='Predicted Mean (FNN)')\n",
    "plt.title('Moon Rock: Simulated Actual and Predicted Real Permittivity')\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Value')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
